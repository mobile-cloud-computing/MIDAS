{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import ntpath\n",
    "import os\n",
    "from PIL import Image\n",
    "from numpy import asarray\n",
    "import pickle\n",
    "import time\n",
    "from sklearn.ensemble._forest import ForestClassifier, ForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to Extract Frames from Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_to_frames(input_loc, output_loc):\n",
    "    \"\"\"Function to extract frames from input video file\n",
    "    and save them as separate frames in an output directory.\n",
    "    Args:\n",
    "        input_loc: Input video file.\n",
    "        output_loc: Output directory to save the frames.\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        os.mkdir(output_loc)\n",
    "    except OSError:\n",
    "        pass\n",
    "    # Log the time\n",
    "    time_start = time.time()\n",
    "    # Start capturing the feed\n",
    "    cap = cv2.VideoCapture(input_loc)\n",
    "    # Find the number of frames\n",
    "    video_length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT)) - 1\n",
    "    print (\"Number of frames: \", video_length)\n",
    "    count = 0\n",
    "    print (\"Converting video..\\n\")\n",
    "    # Start converting the video\n",
    "    while cap.isOpened():\n",
    "        # Extract the frame\n",
    "        ret, frame = cap.read()\n",
    "        #print(frame.shape)\n",
    "        #print(frame[0])\n",
    "        #print(np.amax(frame))\n",
    "        #break\n",
    "        # Write the results back to output location.\n",
    "        cv2.imwrite(output_loc + \"/%#05d.jpg\" % (count+1), frame)\n",
    "        count = count + 1\n",
    "        # If there are no more frames left\n",
    "        if (count > (video_length-1)):\n",
    "            # Log the time again\n",
    "            time_end = time.time()\n",
    "            # Release the feed\n",
    "            cap.release()\n",
    "            # Print stats\n",
    "            print (\"Done extracting frames.\\n%d frames extracted\" % count)\n",
    "            print (\"It took %d seconds for conversion.\" % (time_end-time_start))\n",
    "            break\n",
    "    return count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frameconversion():\n",
    "    print (\"\\n Converting frames . . .\\n\")\n",
    "    filelist=glob.glob('C:/Users/aaqib/Desktop/Midas - Multiple Objects/frames/*.jpg')\n",
    "    for i in filelist:\n",
    "        image = cv2.imread(i)\n",
    "        #print(type(image))\n",
    "        #print(image[0])\n",
    "\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        blurred = cv2.GaussianBlur(gray, (11, 11), cv2.BORDER_DEFAULT)\n",
    "        ret,th1 = cv2.threshold(blurred,170,255,cv2.THRESH_BINARY)\n",
    "\n",
    "\n",
    "        # gaussian_thresh= cv2.adaptiveThreshold(blurred,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY,201,0)\n",
    "\n",
    "        #cv2.imshow(\"binary\",th1)\n",
    "\n",
    "        #cv2.waitKey(0)\n",
    "        #cv2.destroyAllWindows()\n",
    "\n",
    "        # original = image.copy()\n",
    "        # gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        # blurred = cv2.GaussianBlur(gray, (3, 3), 0)\n",
    "        # #canny = cv2.Canny(blurred, 120, 255, 1)\n",
    "        # #kernel = np.ones((5,5),np.uint8)\n",
    "        # #dilate = cv2.dilate(canny, kernel, iterations=1)\n",
    "        filename=ntpath.basename(i)\n",
    "        pre=filename.split(\".\")[0]\n",
    "        fi='C:/Users/aaqib/Desktop/Midas - Multiple Objects/step2/'+pre+\".jpg\"\n",
    "        cv2.imwrite(fi,th1)\n",
    "    print (\"Applied Gaussian Blur and Threshold . . .\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove the FLIR Logo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeflir():\n",
    "    filelist=glob.glob('C:/Users/aaqib/Desktop/Midas - Multiple Objects/step2/*.jpg')\n",
    "    for i in filelist:\n",
    "        image=cv2.imread(i)\n",
    "        rectangle = np.array([[3,475],[160, 475], [165, 405], [7, 405]])\n",
    "        color = [0, 0, 0] #black\n",
    "        cv2.fillConvexPoly(image, rectangle, color)\n",
    "        filename=ntpath.basename(i)\n",
    "        pre=filename.split(\".\")[0]\n",
    "        fi='C:/Users/aaqib/Desktop/Midas - Multiple Objects/step2/'+pre+\".jpg\"\n",
    "        cv2.imwrite(fi,image)\n",
    "    print (\"Removed FLIR watermark . . .\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find ROIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "filelist=glob.glob('C:/Users/aaqib/Desktop/Midas - Multiple Objects/step2/*.jpg')\n",
    "image_number = 0\n",
    "for i in filelist:\n",
    "    image = cv2.imread(i)\n",
    "    original = image.copy()\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    blurred = cv2.GaussianBlur(gray, (3, 3), 0)\n",
    "    canny = cv2.Canny(blurred, 120, 255, 1)\n",
    "    kernel = np.ones((5,5),np.uint8)\n",
    "    dilate = cv2.dilate(canny, kernel, iterations=1)\n",
    "\n",
    "    # Find contours\n",
    "    cnts = cv2.findContours(dilate, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "    obj=1\n",
    "    for c in cnts:\n",
    "        if(obj==1):\n",
    "            x1,y1,w1,h1 = cv2.boundingRect(c)\n",
    "            obj+=1\n",
    "        else:\n",
    "            x2,y2,w2,h2 = cv2.boundingRect(c)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separate the Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n        for j in range(2):\\n            if(j==0):\\n                x,y,w,h=x1,y1,w1,h1\\n                path=\"C:/Users/dar/Desktop/Midas - Multiple Objects/OBJ1/\"\\n            else:\\n                x,y,w,h=x2,y2,w2,h2\\n                path=\"C:/Users/dar/Desktop/Midas - Multiple Objects/OBJ2/\"\\n            #x,y,w,h = cv2.boundingRect(c)\\n            #print(x,y,w,h)\\n            cv2.rectangle(image, (x, y), (x + w, y + h), (36,255,12), 2)\\n            #cv2.rectangle(image, (x, y), (x + w, y + h), (36,255,12), 2)\\n            ROI = original[y-100:y+h+100, x-100:x+w+100]\\n            cv2.imwrite(path+\"{}.jpg\".format(image_number), ROI)\\n            image_number += 1\\n'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def objectseparation():\n",
    "    filelist=glob.glob('C:/Users/aaqib/Desktop/Midas - Multiple Objects/step2/*.jpg')\n",
    "    image_number = 0\n",
    "    for i in filelist:\n",
    "        image = cv2.imread(i)\n",
    "        original = image.copy()\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        blurred = cv2.GaussianBlur(gray, (3, 3), 0)\n",
    "        canny = cv2.Canny(blurred, 120, 255, 1)\n",
    "        kernel = np.ones((5,5),np.uint8)\n",
    "        dilate = cv2.dilate(canny, kernel, iterations=1)\n",
    "\n",
    "        # Find contours\n",
    "        cnts = cv2.findContours(dilate, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "        df = pd.DataFrame(columns = ['X', 'Y', 'W','H'])\n",
    "        for c in cnts:\n",
    "            x,y,w,h = cv2.boundingRect(c)\n",
    "            df = df.append({'X' : x, 'Y' : y, 'W' : w,'H' : h}, ignore_index = True)\n",
    "        #print(df)\n",
    "        obj=1\n",
    "        for c in cnts:\n",
    "            if(obj==1):\n",
    "                x1,y1,w1,h1 = cv2.boundingRect(c)\n",
    "                \n",
    "                obj+=1\n",
    "            else:\n",
    "                x2,y2,w2,h2 = cv2.boundingRect(c)\n",
    "        break\n",
    "    #print(x1,y1,w1,h1)\n",
    "    #print(x2,y2,w2,h2)\n",
    "    filelist=glob.glob('C:/Users/aaqib/Desktop/Midas - Multiple Objects/step2/*.jpg')\n",
    "    image_number = 0\n",
    "    for i in filelist:\n",
    "        image = cv2.imread(i)\n",
    "        original = image.copy()\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        blurred = cv2.GaussianBlur(gray, (3, 3), 0)\n",
    "        canny = cv2.Canny(blurred, 120, 255, 1)\n",
    "        kernel = np.ones((5,5),np.uint8)\n",
    "        dilate = cv2.dilate(canny, kernel, iterations=1)\n",
    "        \n",
    "      \n",
    "        for j in range(df.shape[0]):\n",
    "            x,y,w,h= df.iloc[j]['X'],df.iloc[j]['Y'],df.iloc[j]['W'],df.iloc[j]['H']# x1,y1,w1,h1\n",
    "            path=\"C:/Users/aaqib/Desktop/Midas - Multiple Objects//OBJ\"+str(j+1)+\"/\"\n",
    "            \n",
    "            cv2.rectangle(image, (x, y), (x + w, y + h), (36,255,12), 2)\n",
    "            #cv2.rectangle(image, (x, y), (x + w, y + h), (36,255,12), 2)\n",
    "            #ROI = original[y-100:y+h+100, x-100:x+w+100]\n",
    "            ROI = original[y-20:y+h+20, x-20:x+w+20]\n",
    "            cv2.imwrite(path+\"{}.jpg\".format(image_number), ROI)\n",
    "            image_number += 1\n",
    "    return(df.shape[0])\n",
    "            \n",
    "'''\n",
    "\n",
    "        for j in range(2):\n",
    "            if(j==0):\n",
    "                x,y,w,h=x1,y1,w1,h1\n",
    "                path=\"C:/Users/dar/Desktop/Midas - Multiple Objects/OBJ1/\"\n",
    "            else:\n",
    "                x,y,w,h=x2,y2,w2,h2\n",
    "                path=\"C:/Users/dar/Desktop/Midas - Multiple Objects/OBJ2/\"\n",
    "            #x,y,w,h = cv2.boundingRect(c)\n",
    "            #print(x,y,w,h)\n",
    "            cv2.rectangle(image, (x, y), (x + w, y + h), (36,255,12), 2)\n",
    "            #cv2.rectangle(image, (x, y), (x + w, y + h), (36,255,12), 2)\n",
    "            ROI = original[y-100:y+h+100, x-100:x+w+100]\n",
    "            cv2.imwrite(path+\"{}.jpg\".format(image_number), ROI)\n",
    "            image_number += 1\n",
    "'''\n",
    "            #area = cv2.contourArea(c)\n",
    "            #print(area)\n",
    "    #     cv2.imshow('canny', canny)\n",
    "    #     cv2.imshow('image', image)\n",
    "    #     cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Get Information about White Parts \n",
    "def datapreprocessing(objectlocation):\n",
    "    filelist=sorted(glob.glob(objectlocation),key=os.path.getmtime)\n",
    "    \n",
    "    result_array = np.array([])\n",
    "    result_array1 = np.array([])\n",
    "\n",
    "    counter = 0\n",
    "    for i in filelist:\n",
    "        if counter == 20:\n",
    "            counter = 0\n",
    "            image = cv2.imread(i)\n",
    "            occurrences = np.count_nonzero(image == 255)\n",
    "            result_array = np.append(result_array, occurrences)\n",
    "            #print(occurrences)\n",
    "        counter += 1\n",
    "\n",
    "    startvalue=result_array[0]\n",
    "\n",
    "    data=np.array([])\n",
    "\n",
    "    counter = 0\n",
    "    sample = []\n",
    "    samples = []\n",
    "    #extract normalised data\n",
    "    for i in result_array:\n",
    "        if counter == 10:\n",
    "            samples.append(sample)\n",
    "            sample = []\n",
    "            counter = 0\n",
    "        devvalue=float(startvalue-i)/float(startvalue)\n",
    "    #     print(devvalue)\n",
    "        normvalue=1-devvalue\n",
    "        #print(normvalue)\n",
    "        sample.append(normvalue)\n",
    "        counter += 1\n",
    "\n",
    "    samples_np = np.array(samples)\n",
    "    samples_np.shape \n",
    "    print(\"Created .npz file\")\n",
    "    #     data=np.append(data,normvalue)\n",
    "    \n",
    "    return samples\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixedholdprediction(test):\n",
    "    data = test['samples']\n",
    "    X=np.array(data)\n",
    "    \n",
    "    # Load the Saved Model back from file\n",
    "    with open(\"C:/Users/aaqib/Desktop/Midas - Multiple Objects/saved models/Fixed_Model.pkl\", 'rb') as file:  \n",
    "        Model = pickle.load(file)\n",
    "    result=Model.predict(X)\n",
    "    uniqueclasses,count_class=np.unique(result,return_counts=True)\n",
    "    predictedindex=np.argmax(count_class)\n",
    "    classresult=uniqueclasses[predictedindex]\n",
    "    return classresult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naturalholdprediction(test):\n",
    "    data = test['samples']\n",
    "    X=np.array(data)\n",
    "    \n",
    "    # Load the Saved Model back from file\n",
    "    with open(\"C:/Users/aaqib/Desktop/Midas - Multiple Objects/saved models/Natural_Model.pkl\", 'rb') as file:  \n",
    "        Model = pickle.load(file)\n",
    "    result=Model.predict(X)\n",
    "    uniqueclasses,count_class=np.unique(result,return_counts=True)\n",
    "    predictedindex=np.argmax(count_class)\n",
    "    classresult=uniqueclasses[predictedindex]\n",
    "    return classresult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combinedprediction(test):\n",
    "    data = test['samples']\n",
    "    X=np.array(data)\n",
    "    \n",
    "    # Load the Saved Model back from file\n",
    "    with open(\"C:/Users/aaqib/Desktop/Midas - Multiple Objects/saved models/Combined_Model.pkl\", 'rb') as file:  \n",
    "        Model = pickle.load(file)\n",
    "    result=Model.predict(X)\n",
    "    uniqueclasses,count_class=np.unique(result,return_counts=True)\n",
    "    predictedindex=np.argmax(count_class)\n",
    "    classresult=uniqueclasses[predictedindex]\n",
    "    return classresult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deleteimages(df_size):\n",
    "    \n",
    "    files = glob.glob('C:/Users/aaqib/Desktop/Midas - Multiple Objects/frames/*.jpg')\n",
    "    for f in files:\n",
    "        os.remove(f)\n",
    "    files = glob.glob('C:/Users/aaqib/Desktop/Midas - Multiple Objects/step2/*.jpg')\n",
    "    for f in files:\n",
    "        os.remove(f)\n",
    "    for i in range(df_size):\n",
    "        files = glob.glob('C:/Users/aaqib/Desktop/Midas - Multiple Objects/OBJ'+str(i+1)+'/*.jpg')\n",
    "        for f in files:\n",
    "            os.remove(f)\n",
    "    print(\"Done deleting files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of frames:  493\n",
      "Converting video..\n",
      "\n",
      "Done extracting frames.\n",
      "493 frames extracted\n",
      "It took 2 seconds for conversion.\n",
      "\n",
      " Converting frames . . .\n",
      "\n",
      "Applied Gaussian Blur and Threshold . . .\n",
      "\n",
      "Removed FLIR watermark . . .\n",
      "\n",
      "Created .npz file\n",
      "\n",
      "For Object 1: \n",
      "\n",
      "Fixed Hold Model Result: The material belongs to Class :  0\n",
      "Natural Hold Model Result: The material belongs to Class :  0\n",
      "Combined Model Result: The material belongs to Class :  0\n",
      "Created .npz file\n",
      "\n",
      "For Object 2: \n",
      "\n",
      "Fixed Hold Model Result: The material belongs to Class :  0\n",
      "Natural Hold Model Result: The material belongs to Class :  0\n",
      "Combined Model Result: The material belongs to Class :  0\n",
      "Created .npz file\n",
      "\n",
      "For Object 3: \n",
      "\n",
      "Fixed Hold Model Result: The material belongs to Class :  0\n",
      "Natural Hold Model Result: The material belongs to Class :  0\n",
      "Combined Model Result: The material belongs to Class :  0\n",
      "Created .npz file\n",
      "\n",
      "For Object 4: \n",
      "\n",
      "Fixed Hold Model Result: The material belongs to Class :  0\n",
      "Natural Hold Model Result: The material belongs to Class :  0\n",
      "Combined Model Result: The material belongs to Class :  0\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20376/3332170193.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0msamplesobj1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdatapreprocessing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'C:/Users/aaqib/Desktop/Midas - Multiple Objects/OBJ'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'/*.jpg'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m         \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msavez_compressed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'npzfileobj'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msamples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msamplesobj1\u001b[0m\u001b[1;33m)\u001b[0m   \u001b[1;31m#name of .npz file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20376/1780465930.py\u001b[0m in \u001b[0;36mdatapreprocessing\u001b[1;34m(objectlocation)\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mcounter\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[0mstartvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresult_array\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "if __name__==\"__main__\":\n",
    "    \n",
    "    s = time.process_time()\n",
    "    input_loc = 'C:/Users/aaqib/Desktop/Midas - Multiple Objects/Videos/FourObjects.mp4'\n",
    "    output_loc = 'C:/Users/aaqib/Desktop/Midas - Multiple Objects/frames'\n",
    "    video_to_frames(input_loc, output_loc)\n",
    "    frameconversion()\n",
    "    removeflir()\n",
    "    df_size = objectseparation()\n",
    "    \n",
    "    for i in range(df_size):\n",
    "        samplesobj1=datapreprocessing('C:/Users/aaqib/Desktop/Midas - Multiple Objects/OBJ'+str(i+1)+'/*.jpg')\n",
    "        np.savez_compressed('npzfileobj'+str(i+1), samples=samplesobj1)   #name of .npz file\n",
    "        \n",
    "        test = np.load('npzfileobj'+str(i+1)+'.npz')\n",
    "        print(\"\\nFor Object \"+str(i+1)+\": \\n\")\n",
    "        result1=fixedholdprediction(test)\n",
    "        result2=naturalholdprediction(test)\n",
    "        result3=combinedprediction(test)\n",
    "        print(\"Fixed Hold Model Result: The material belongs to Class : \", result1)\n",
    "        print(\"Natural Hold Model Result: The material belongs to Class : \", result2)\n",
    "        print(\"Combined Model Result: The material belongs to Class : \", result3)\n",
    "    \n",
    "    '''\n",
    "    samplesobj1=datapreprocessing('C:/Users/dar/Desktop/Midas - Multiple Objects/OBJ1/*.jpg')\n",
    "    np.savez_compressed('npzfileobj1', samples=samplesobj1)   #name of .npz file\n",
    "    samplesobj2=datapreprocessing('C:/Users/dar/Desktop/Midas - Multiple Objects/OBJ2/*.jpg')\n",
    "    np.savez_compressed('npzfileobj2', samples=samplesobj2)   #name of .npz file\n",
    "    \n",
    "    #Load the File for Object 1 \n",
    "    test = np.load('npzfileobj1.npz')\n",
    "    print(\"\\nFor Object 1: \\n\")\n",
    "    result1=fixedholdprediction(test)\n",
    "    result2=naturalholdprediction(test)\n",
    "    result3=combinedprediction(test)\n",
    "    print(\"Fixed Hold Model Result: The material belongs to Class : \", result1)\n",
    "    print(\"Natural Hold Model Result: The material belongs to Class : \", result2)\n",
    "    print(\"Combined Model Result: The material belongs to Class : \", result3)\n",
    "    \n",
    "    #Load the File for Object 2\n",
    "    test1 = np.load('npzfileobj2.npz')\n",
    "    print(\"\\nFor Object 2: \\n\")\n",
    "    result11=fixedholdprediction(test1)\n",
    "    result22=naturalholdprediction(test1)\n",
    "    result33=combinedprediction(test1)\n",
    "    print(\"Fixed Hold Model Result: The material belongs to Class : \", result11)\n",
    "    print(\"Natural Hold Model Result: The material belongs to Class : \", result22)\n",
    "    print(\"Combined Model Result: The material belongs to Class : \", result33)\n",
    "    '''\n",
    "    e = time.process_time()\n",
    "    print(\"Time Taken: \",e-s)\n",
    "    deletee=input(\"Do you want to remove the contents of folders(y or n):\")\n",
    "    if (deletee=='y'):\n",
    "        deleteimages(df_size)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To Calculate ROI of Different Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "filelist=glob.glob('C:/Users/dar/Desktop/Midas - Multiple Objects/step2/*.jpg')\n",
    "image_number = 0\n",
    "for i in filelist:\n",
    "    image = cv2.imread(i)\n",
    "    original = image.copy()\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    blurred = cv2.GaussianBlur(gray, (3, 3), 0)\n",
    "    canny = cv2.Canny(blurred, 120, 255, 1)\n",
    "    kernel = np.ones((5,5),np.uint8)\n",
    "    dilate = cv2.dilate(canny, kernel, iterations=1)\n",
    "\n",
    "    # Find contours\n",
    "    cnts = cv2.findContours(dilate, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "\n",
    "    # Iterate thorugh contours and filter for ROI\n",
    "   \n",
    "    for c in cnts:\n",
    "        x,y,w,h = cv2.boundingRect(c)\n",
    "        cv2.rectangle(image, (x, y), (x + w, y + h), (36,255,12), 2)\n",
    "        ROI = original[y:y+h, x:x+w]\n",
    "        #cv2.imwrite(\"{} ROI.png\".format(image_number), ROI)\n",
    "        image_number += 1\n",
    "        area = cv2.contourArea(c)\n",
    "        #print(area)\n",
    "        filename=ntpath.basename(i)\n",
    "        pre=filename.split(\".\")[0]\n",
    "        fi='C:/Users/dar/Desktop/Midas - Multiple Objects/rois/'+pre+\".jpg\"\n",
    "        cv2.imwrite(fi,image)\n",
    "        #area = cv2.contourArea(c)\n",
    "        #print(area)\n",
    "#     cv2.imshow('canny', canny)\n",
    "#     cv2.imshow('image', image)\n",
    "#     cv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
