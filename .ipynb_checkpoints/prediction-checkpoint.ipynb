{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import ntpath\n",
    "import os\n",
    "from PIL import Image\n",
    "from numpy import asarray\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to Extract Frames from Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_to_frames(input_loc, output_loc):\n",
    "    \"\"\"Function to extract frames from input video file\n",
    "    and save them as separate frames in an output directory.\n",
    "    Args:\n",
    "        input_loc: Input video file.\n",
    "        output_loc: Output directory to save the frames.\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        os.mkdir(output_loc)\n",
    "    except OSError:\n",
    "        pass\n",
    "    # Log the time\n",
    "    time_start = time.time()\n",
    "    # Start capturing the feed\n",
    "    cap = cv2.VideoCapture(input_loc)\n",
    "    # Find the number of frames\n",
    "    video_length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT)) - 1\n",
    "    print (\"Number of frames: \", video_length)\n",
    "    count = 0\n",
    "    print (\"Converting video..\\n\")\n",
    "    # Start converting the video\n",
    "    while cap.isOpened():\n",
    "        # Extract the frame\n",
    "        ret, frame = cap.read()\n",
    "        #print(frame.shape)\n",
    "        #print(frame[0])\n",
    "        #print(np.amax(frame))\n",
    "        #break\n",
    "        # Write the results back to output location.\n",
    "        cv2.imwrite(output_loc + \"/%#05d.jpg\" % (count+1), frame)\n",
    "        count = count + 1\n",
    "        # If there are no more frames left\n",
    "        if (count > (video_length-1)):\n",
    "            # Log the time again\n",
    "            time_end = time.time()\n",
    "            # Release the feed\n",
    "            cap.release()\n",
    "            # Print stats\n",
    "            print (\"Done extracting frames.\\n%d frames extracted\" % count)\n",
    "            print (\"It took %d seconds for conversion.\" % (time_end-time_start))\n",
    "            break\n",
    "    return count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frameconversion():\n",
    "    print (\"\\n Converting frames . . .\\n\")\n",
    "    filelist=glob.glob('./frames/*.jpg')\n",
    "    for i in filelist:\n",
    "        image = cv2.imread(i)\n",
    "        #print(type(image))\n",
    "        #print(image[0])\n",
    "\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        blurred = cv2.GaussianBlur(gray, (11, 11), cv2.BORDER_DEFAULT)\n",
    "        ret,th1 = cv2.threshold(blurred,170,255,cv2.THRESH_BINARY)\n",
    "\n",
    "\n",
    "        # gaussian_thresh= cv2.adaptiveThreshold(blurred,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY,201,0)\n",
    "\n",
    "        #cv2.imshow(\"binary\",th1)\n",
    "\n",
    "        #cv2.waitKey(0)\n",
    "        #cv2.destroyAllWindows()\n",
    "\n",
    "        # original = image.copy()\n",
    "        # gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        # blurred = cv2.GaussianBlur(gray, (3, 3), 0)\n",
    "        # #canny = cv2.Canny(blurred, 120, 255, 1)\n",
    "        # #kernel = np.ones((5,5),np.uint8)\n",
    "        # #dilate = cv2.dilate(canny, kernel, iterations=1)\n",
    "        filename=ntpath.basename(i)\n",
    "        pre=filename.split(\".\")[0]\n",
    "        fi='./step2/'+pre+\".jpg\"\n",
    "        cv2.imwrite(fi,th1)\n",
    "    print (\"Applied Gaussian Blur and Threshold . . .\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Get Information about White Parts \n",
    "def datapreprocessing():\n",
    "    filelist=glob.glob('./step2/*.jpg')\n",
    "    result_array = np.array([])\n",
    "\n",
    "    counter = 0\n",
    "    for i in filelist:\n",
    "        if counter == 20:\n",
    "            counter = 0\n",
    "            image = cv2.imread(i)\n",
    "            occurrences = np.count_nonzero(image == 255)\n",
    "            result_array = np.append(result_array, occurrences)\n",
    "            #print(occurrences)\n",
    "        counter += 1\n",
    "    #print(type(result_array[0]))\n",
    "    \n",
    "    ## Normalise The DATA and save the Normalised Data to NPZ File\n",
    "\n",
    "    startvalue=result_array[0]\n",
    "\n",
    "    data=np.array([])\n",
    "\n",
    "    counter = 0\n",
    "    sample = []\n",
    "    samples = []\n",
    "    #extract normalised data\n",
    "    for i in result_array:\n",
    "        if counter == 10:\n",
    "            samples.append(sample)\n",
    "            sample = []\n",
    "            counter = 0\n",
    "        devvalue=float(startvalue-i)/float(startvalue)\n",
    "    #     print(devvalue)\n",
    "        normvalue=1-devvalue\n",
    "        #print(normvalue)\n",
    "        sample.append(normvalue)\n",
    "        counter += 1\n",
    "\n",
    "    samples_np = np.array(samples)\n",
    "    samples_np.shape\n",
    "    np.savez_compressed('npzfile', samples=samples)   #name of .npz file \n",
    "    print(\"Created .npz file\")\n",
    "    #     data=np.append(data,normvalue)\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixedholdprediction():\n",
    "    test = np.load('npzfile.npz')\n",
    "    data = test['samples']\n",
    "    X=np.array(data)\n",
    "    \n",
    "    # Load the Saved Model back from file\n",
    "    with open(\"saved models/Fixedhold_Model.pkl\", 'rb') as file:  \n",
    "        Model = pickle.load(file)\n",
    "    result=Model.predict(X)\n",
    "    uniqueclasses,count_class=np.unique(result,return_counts=True)\n",
    "    predictedindex=np.argmax(count_class)\n",
    "    classresult=uniqueclasses[predictedindex]\n",
    "    return classresult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naturalholdprediction():\n",
    "    test = np.load('npzfile.npz')\n",
    "    data = test['samples']\n",
    "    X=np.array(data)\n",
    "    \n",
    "    # Load the Saved Model back from file\n",
    "    with open(\"saved models/Naturalhold_Model.pkl\", 'rb') as file:  \n",
    "        Model = pickle.load(file)\n",
    "    result=Model.predict(X)\n",
    "    uniqueclasses,count_class=np.unique(result,return_counts=True)\n",
    "    predictedindex=np.argmax(count_class)\n",
    "    classresult=uniqueclasses[predictedindex]\n",
    "    return classresult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combinedprediction():\n",
    "    test = np.load('npzfile.npz')\n",
    "    data = test['samples']\n",
    "    X=np.array(data)\n",
    "    \n",
    "    # Load the Saved Model back from file\n",
    "    with open(\"saved models/Combined_Model.pkl\", 'rb') as file:  \n",
    "        Model = pickle.load(file)\n",
    "    result=Model.predict(X)\n",
    "    uniqueclasses,count_class=np.unique(result,return_counts=True)\n",
    "    predictedindex=np.argmax(count_class)\n",
    "    classresult=uniqueclasses[predictedindex]\n",
    "    return classresult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of frames:  970\n",
      "Converting video..\n",
      "\n",
      "Done extracting frames.\n",
      "970 frames extracted\n",
      "It took 22 seconds for conversion.\n",
      "\n",
      " Converting frames . . .\n",
      "\n",
      "Applied Gaussian Blur and Threshold . . .\n",
      "\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-1469c90e75e9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mvideo_to_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_loc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_loc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mframeconversion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mdatapreprocessing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mresult1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfixedholdprediction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mresult2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnaturalholdprediction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-5f1f446bb76d>\u001b[0m in \u001b[0;36mdatapreprocessing\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;31m## Normalise The DATA and save the Normalised Data to NPZ File\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[0mstartvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresult_array\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "if __name__==\"__main__\":\n",
    "\n",
    "    input_loc = 'C:/Users/dar/Desktop/thermal vids/P 2.mp4'\n",
    "    output_loc = 'C:/Users/dar/Desktop/thermal vids/frames/'\n",
    "    video_to_frames(input_loc, output_loc)\n",
    "    frameconversion()\n",
    "    datapreprocessing()\n",
    "    result1=fixedholdprediction()\n",
    "    result2=naturalholdprediction()\n",
    "    result3=combinedprediction()\n",
    "    print(\"Fixed Hold Model Result: The material belongs to Class : \", result1)\n",
    "    print(\"Natural Hold Model Result: The material belongs to Class : \", result2)\n",
    "    print(\"Combined Model Result: The material belongs to Class : \", result3)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
